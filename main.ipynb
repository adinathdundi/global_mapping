{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5b10ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-stack\n",
      "  Downloading llama_stack-0.2.12-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting aiohttp (from llama-stack)\n",
      "  Downloading aiohttp-3.12.13-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting fastapi<1.0,>=0.115.0 (from llama-stack)\n",
      "  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting fire (from llama-stack)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "     ---------------------------------------- 0.0/87.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 87.2/87.2 kB 4.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting httpx (from llama-stack)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub (from llama-stack)\n",
      "  Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting jinja2>=3.1.6 (from llama-stack)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema (from llama-stack)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting llama-stack-client>=0.2.12 (from llama-stack)\n",
      "  Downloading llama_stack_client-0.2.12-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting openai>=1.66 (from llama-stack)\n",
      "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: prompt-toolkit in .\\.venv\\lib\\site-packages (from llama-stack) (3.0.51)\n",
      "Collecting python-dotenv (from llama-stack)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-jose (from llama-stack)\n",
      "  Downloading python_jose-3.5.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pydantic>=2 (from llama-stack)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "     ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 68.0/68.0 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting requests (from llama-stack)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting rich (from llama-stack)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: setuptools in .\\.venv\\lib\\site-packages (from llama-stack) (65.5.0)\n",
      "Collecting starlette (from llama-stack)\n",
      "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting termcolor (from llama-stack)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting tiktoken (from llama-stack)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting pillow (from llama-stack)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting h11>=0.16.0 (from llama-stack)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting python-multipart>=0.0.20 (from llama-stack)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting starlette (from llama-stack)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in .\\.venv\\lib\\site-packages (from fastapi<1.0,>=0.115.0->llama-stack) (4.14.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=3.1.6->llama-stack)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting click (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting distro<2,>=1.7.0 (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pandas (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Using cached pandas-2.3.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pyaml (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sniffio (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting certifi (from httpx->llama-stack)\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-stack)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx->llama-stack)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.66->llama-stack)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2->llama-stack)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2->llama-stack)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2->llama-stack)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->llama-stack)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->llama-stack)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->llama-stack)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->llama-stack)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->llama-stack)\n",
      "  Downloading multidict-6.6.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->llama-stack)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->llama-stack)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 76.3/76.3 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting filelock (from huggingface-hub->llama-stack)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->llama-stack)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in .\\.venv\\lib\\site-packages (from huggingface-hub->llama-stack) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub->llama-stack)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->llama-stack)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->llama-stack)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->llama-stack)\n",
      "  Downloading rpds_py-0.25.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: wcwidth in .\\.venv\\lib\\site-packages (from prompt-toolkit->llama-stack) (0.2.13)\n",
      "Collecting ecdsa!=0.15 (from python-jose->llama-stack)\n",
      "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Collecting rsa!=4.1.1,!=4.4,<5.0,>=4.0 (from python-jose->llama-stack)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.5.0 (from python-jose->llama-stack)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->llama-stack)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->llama-stack)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->llama-stack)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\.venv\\lib\\site-packages (from rich->llama-stack) (2.19.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->llama-stack)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in .\\.venv\\lib\\site-packages (from ecdsa!=0.15->python-jose->llama-stack) (1.17.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->llama-stack)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm->llama-stack-client>=0.2.12->llama-stack) (0.4.6)\n",
      "Collecting numpy>=1.23.2 (from pandas->llama-stack-client>=0.2.12->llama-stack)\n",
      "  Using cached numpy-2.3.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-stack-client>=0.2.12->llama-stack)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-stack-client>=0.2.12->llama-stack)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading llama_stack-0.2.12-py3-none-any.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.4/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.7 MB 6.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.8/3.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.1/3.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.3/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.5/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.7 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.0/3.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.2/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.4/3.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.7/3.7 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.9/3.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.2/3.7 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.5/3.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n",
      "   ---------------------------------------- 0.0/95.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 95.5/95.5 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.9/134.9 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading llama_stack_client-0.2.12-py3-none-any.whl (340 kB)\n",
      "   ---------------------------------------- 0.0/340.2 kB ? eta -:--:--\n",
      "   ------------------- ------------------- 174.1/340.2 kB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 340.2/340.2 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "   ---------------------------------------- 0.0/755.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 184.3/755.0 kB 5.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 348.2/755.0 kB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 583.7/755.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/755.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/755.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/755.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/755.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/755.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 755.0/755.0 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "   ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 204.8/444.8 kB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 409.6/444.8 kB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 444.8/444.8 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/2.0 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/2.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.0/72.0 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.13-cp311-cp311-win_amd64.whl (451 kB)\n",
      "   ---------------------------------------- 0.0/451.4 kB ? eta -:--:--\n",
      "   ------------------- ------------------- 225.3/451.4 kB 14.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 368.6/451.4 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 451.4/451.4 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "   ---------------------------------------- 0.0/515.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 225.3/515.4 kB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 471.0/515.4 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 515.4/515.4 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.7 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 81.9/88.7 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 88.7/88.7 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.5/2.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.7 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.0/2.7 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.7 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.5/2.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading python_jose-3.5.0-py2.py3-none-any.whl (34 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.8/64.8 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.2 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 215.0/243.2 kB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 243.2/243.2 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 225.3/893.9 kB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 522.2/893.9 kB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 819.2/893.9 kB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 893.9/893.9 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.9/100.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.8/63.8 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "   ---------------------------------------- 0.0/157.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 157.7/157.7 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
      "   ---------------------------------------- 0.0/150.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 150.6/150.6 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.0/44.0 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 199.1/199.1 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.2/209.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading multidict-6.6.3-cp311-cp311-win_amd64.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.9/45.9 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.1/83.1 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.0/162.0 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.1 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 235.5/274.1 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.1/274.1 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading rpds_py-0.25.1-cp311-cp311-win_amd64.whl (231 kB)\n",
      "   ---------------------------------------- 0.0/231.6 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 194.6/231.6 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 231.6/231.6 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 129.8/129.8 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.7/86.7 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.2/102.2 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached pandas-2.3.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Downloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached numpy-2.3.1-cp311-cp311-win_amd64.whl (13.0 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (pyproject.toml): started\n",
      "  Building wheel for fire (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114349 sha256=07bf9d71c00e2e33807a5831354e8cab49698dc8742c19a72c52ff66d3ab03b2\n",
      "  Stored in directory: c:\\users\\adina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\46\\54\\24\\1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
      "Successfully built fire\n",
      "Installing collected packages: pytz, urllib3, tzdata, typing-inspection, tqdm, termcolor, sniffio, rpds-py, regex, pyyaml, python-multipart, python-dotenv, pydantic-core, pyasn1, propcache, pillow, numpy, multidict, mdurl, MarkupSafe, jiter, idna, h11, fsspec, frozenlist, filelock, ecdsa, distro, click, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, rsa, requests, referencing, pydantic, pyaml, pandas, markdown-it-py, jinja2, httpcore, fire, anyio, aiosignal, tiktoken, starlette, rich, python-jose, jsonschema-specifications, huggingface-hub, httpx, aiohttp, openai, llama-stack-client, jsonschema, fastapi, llama-stack\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 certifi-2025.6.15 charset_normalizer-3.4.2 click-8.2.1 distro-1.9.0 ecdsa-0.19.1 fastapi-0.115.14 filelock-3.18.0 fire-0.7.0 frozenlist-1.7.0 fsspec-2025.5.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.33.1 idna-3.10 jinja2-3.1.6 jiter-0.10.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 llama-stack-0.2.12 llama-stack-client-0.2.12 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.6.3 numpy-2.3.1 openai-1.93.0 pandas-2.3.0 pillow-11.2.1 propcache-0.3.2 pyaml-25.5.0 pyasn1-0.6.1 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 python-jose-3.5.0 python-multipart-0.0.20 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.4 rich-14.0.0 rpds-py-0.25.1 rsa-4.9.1 sniffio-1.3.1 starlette-0.46.2 termcolor-3.1.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9d4f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response from Ollama\n",
      "Jantar Mantar is a historic observatory and astronomical instrument park located in Jaipur, Rajasthan, India. It was built in the 18th century during the reign of Maharaja Sawai Jai Singh II, who was a renowned astronomer and mathematician.\n",
      "\n",
      "The name \"Jantar\" comes from the Sanskrit word \"jantra,\" which means \"instrument.\" The word \"Mantar\" refers to a collection of instruments. So, the name \"Jantar Mantar\" can be literally translated to \"collection of instruments.\"\n",
      "\n",
      "Built between 1734 and 1739, Jantar Mantar is one of the oldest and most accurate astronomical observatories in India. It was designed by Maharaja Sawai Jai Singh II and features a collection of intricate mechanical instruments that were used for various astronomical observations.\n",
      "\n",
      "The park consists of several impressive structures, including:\n",
      "\n",
      "1. The Meghwal Gate: A grand entrance that leads to the observatory.\n",
      "2. The Astronomer's Palace: A large building that houses the main instruments.\n",
      "3. The Alaya dehar: A tower with a hemispherical dome that contains a sundial.\n",
      "4. The Samrat Yantra: An elliptical sundial that is one of the most accurate in the world.\n",
      "5. The Jyotish Mandir: An observatory that houses a large instrument for measuring time and date.\n",
      "\n",
      "The instruments at Jantar Mantar were designed to measure various celestial phenomena, such as:\n",
      "\n",
      "* Time and date\n",
      "* Longitude (the position of the sun, moon, or stars)\n",
      "* Altitude (the angle between the observer's location and the horizon)\n",
      "* Distance from the Sun\n",
      "* Planetary positions\n",
      "\n",
      "Jantar Mantar is a testament to India's rich cultural heritage and its contributions to astronomy. It has been recognized by UNESCO as a World Heritage Site since 2010.\n",
      "\n",
      "Today, Jantar Mantar is a popular tourist destination in Jaipur, attracting visitors from all over the world who come to marvel at its architectural beauty and scientific significance.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "payload = {\n",
    "    'model' : 'llama3.2',\n",
    "    'messages' : [{\"role\": \"user\", \"content\" : \"What is Jantar Mantar\"}] \n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Streaming response from Ollama\")\n",
    "    for line in response.iter_lines(decode_unicode=True):\n",
    "        if line:\n",
    "            try:\n",
    "                json_data = json.loads(line)\n",
    "                if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                    print(json_data[\"message\"][\"content\"],end=\"\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse line: {line}\")\n",
    "    print()\n",
    "\n",
    "else:\n",
    "    print(f\"Error in model {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e2589",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m snomed_refset = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m\"\u001b[39m\u001b[33mrefset_extended_map (1).xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m diag = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdiagnosis.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m merged_df = pd.merge(\n\u001b[32m      5\u001b[39m     snomed_refset,\n\u001b[32m      6\u001b[39m     diag[[\u001b[33m'\u001b[39m\u001b[33mCodeWithSeparator\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLongDescription\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     right_on=\u001b[33m'\u001b[39m\u001b[33mCodeWithSeparator\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m     )\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "'snomed_refset = pd.read_csv(\"refset_extended_map (1).xlsx\")\n",
    "diag = pd.read_csv(\"diagnosis.csv\")\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    snomed_refset,\n",
    "    diag[['CodeWithSeparator', 'LongDescription']],\n",
    "    how='left',\n",
    "    left_on='mapTarget',\n",
    "    right_on='CodeWithSeparator'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8d9ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ ICD Description: Essential (primary) hypertension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High blood pressure\n",
      "38341003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(38341003)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_snomed import best_matching_snomed\n",
    "\n",
    "best_matching_snomed('I10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16919780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ ICD code not found in dataset.\n",
      "ℹ️ ICD Description: None\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for EmbedRequest\ninput.str\n  Input should be a valid string [type=string_type, input_value=[None], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\ninput.json-or-python[json=list[str],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]].0\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m diag.iterrows():\n\u001b[32m      9\u001b[39m     icd_code = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m\"\u001b[39m\u001b[33mCodeWithSeparator\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     snomed_code = \u001b[43mbest_matching_snomed\u001b[49m\u001b[43m(\u001b[49m\u001b[43micd_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     snomed_codes.append(snomed_code)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Add the results to the DataFrame\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\predict_snomed.py:56\u001b[39m, in \u001b[36mbest_matching_snomed\u001b[39m\u001b[34m(icd_code)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m❌ ICD code not found in dataset.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mℹ️ ICD Description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00micd_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m retrieved_docs = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43micd_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m terms = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m retrieved_docs]\n\u001b[32m     59\u001b[39m term_list = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mterm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m terms])  \n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m _kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1079\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1077\u001b[39m _kwargs = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1081\u001b[39m     docs_and_similarities = (\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1083\u001b[39m             query, **_kwargs\n\u001b[32m   1084\u001b[39m         )\n\u001b[32m   1085\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:603\u001b[39m, in \u001b[36mChroma.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, **kwargs)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    586\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    587\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    590\u001b[39m     **kwargs: Any,\n\u001b[32m    591\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m    592\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[32m    593\u001b[39m \n\u001b[32m    594\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    601\u001b[39m \u001b[33;03m        List of documents most similar to the query text.\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:700\u001b[39m, in \u001b[36mChroma.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, where_document, **kwargs)\u001b[39m\n\u001b[32m    692\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.__query_collection(\n\u001b[32m    693\u001b[39m         query_texts=[query],\n\u001b[32m    694\u001b[39m         n_results=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    697\u001b[39m         **kwargs,\n\u001b[32m    698\u001b[39m     )\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     query_embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.__query_collection(\n\u001b[32m    702\u001b[39m         query_embeddings=[query_embedding],\n\u001b[32m    703\u001b[39m         n_results=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    706\u001b[39m         **kwargs,\n\u001b[32m    707\u001b[39m     )\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\langchain_ollama\\embeddings.py:272\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    271\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed query text.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\langchain_ollama\\embeddings.py:265\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    264\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     embedded_docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded_docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\ollama\\_client.py:371\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    360\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    361\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    366\u001b[39m ) -> EmbedResponse:\n\u001b[32m    367\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m    368\u001b[39m     EmbedResponse,\n\u001b[32m    369\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    370\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m/api/embed\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     json=\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    378\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\global_mapping\\.venv\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for EmbedRequest\ninput.str\n  Input should be a valid string [type=string_type, input_value=[None], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\ninput.json-or-python[json=list[str],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]].0\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from predict_snomed import best_matching_snomed  # Make sure this is already defined\n",
    "\n",
    "\n",
    "snomed_codes = []\n",
    "\n",
    "# Loop through each ICD code and get the SNOMED code\n",
    "for index, row in diag.iterrows():\n",
    "    icd_code = str(row[\"CodeWithSeparator\"])\n",
    "    snomed_code = best_matching_snomed(icd_code)\n",
    "    snomed_codes.append(snomed_code)\n",
    "\n",
    "# Add the results to the DataFrame\n",
    "diag[\"SNOMED_CODE\"] = snomed_codes\n",
    "\n",
    "# Optionally save to CSV\n",
    "diag.to_csv(\"icd_to_snomed_mapped.csv\", index=False)\n",
    "\n",
    "print(\"✅ Mapping complete. Output saved to 'icd_to_snomed_mapped.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
